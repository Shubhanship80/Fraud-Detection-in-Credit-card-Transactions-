# -*- coding: utf-8 -*-
"""Fraud_detection_in_Credit_cards_Project (1) (1).ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1oNdS5qjUvXnuwzEvuPgasFtbMjkLxOkd
"""

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.linear_model import LogisticRegression
from sklearn.linear_model import LinearRegression
from sklearn.metrics import confusion_matrix, classification_report, roc_auc_score, roc_curve
import statsmodels.api as sm
from sklearn.neighbors import KNeighborsClassifier
from sklearn.naive_bayes import MultinomialNB
from sklearn.neural_network import MLPClassifier
from sklearn.preprocessing import MinMaxScaler

"""Uploading the Dataset"""

from google.colab import files
uploaded = files.upload()

import io
df = pd.read_csv(io.BytesIO(uploaded['creditcard.csv']))

"""Finding the number of rows and columns"""

df.shape

df.head(5)

df['Amount'].value_counts()

df['Class'].value_counts()

"""Finding the missing value percentage"""

missing_percentage = (df.isnull().sum() / len(df)) * 100


missing_data = pd.DataFrame({'Column': df.columns, 'Missing Percentage': missing_percentage})

# Sorting the DataFrame by missing percentage in descending order
missing_data = missing_data.sort_values(by='Missing Percentage', ascending=False)
missing_data

df.info()

"""Descriptive analysis: Mean, median, Standard deviation

"""

df.describe()

"""Heatmap to highlight missing values"""

sns.heatmap(df.isnull(), cbar=True) #no missing values found

df.corr()['Class'].sort_values(ascending=False)

plt.figure(figsize = (16,5))
sns.heatmap(df.corr(), annot=False, linewidths=.5)

t =df[['Amount','Class']]

sns.pairplot(t, hue = 'Class')

"""Regression model

"""

X = df.drop('Class', axis=1)
y = df['Class']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

model = LogisticRegression()
model.fit(X_train, y_train)

y_pred = model.predict(X_test)

from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
accuracy = accuracy_score(y_test, y_pred)
conf_matrix = confusion_matrix(y_test, y_pred)
classification_rep = classification_report(y_test, y_pred)

print("Accuracy:", accuracy)
print("Confusion Matrix:")
print(conf_matrix)
print("Classification Report:")
print(classification_rep)

from sklearn.metrics import mean_squared_error, r2_score
X = df[['V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10']]
y = df['Amount']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)


regression_model = LinearRegression()
regression_model.fit(X_train, y_train)

y_pred = regression_model.predict(X_test)

# Calculating the  R-squared (R²)
r_squared = r2_score(y_test, y_pred)

# Calculating Mean Squared Error (MSE)
mse = mean_squared_error(y_test, y_pred)

print(f"R-squared (R²): {r_squared}")
print(f"Mean Squared Error (MSE): {mse}")

"""Classification model

"""

from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

X = df.drop('Class', axis=1)
y = df['Class']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)
rf_classifier.fit(X_train, y_train)

y_pred = rf_classifier.predict(X_test)

accuracy = accuracy_score(y_test, y_pred)
conf_matrix = confusion_matrix(y_test, y_pred)
classification_rep = classification_report(y_test, y_pred)
print("Accuracy:", accuracy)
print("Confusion Matrix:")
print(conf_matrix)
print("Classification Report:")
print(classification_rep)

from sklearn.metrics import roc_auc_score, roc_curve, auc
y_pred_proba = rf_classifier.predict_proba(X_test)[:, 1]
auc_roc = roc_auc_score(y_test, y_pred_proba)

print(f"AUC-ROC Score: {auc_roc}")
# Plot ROC curve
fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)
roc_auc = auc(fpr, tpr)

plt.figure()
plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic (ROC) Curve')
plt.legend(loc="lower right")
plt.show()

"""Clustering"""

from sklearn.cluster import KMeans
import matplotlib.pyplot as plt

selected_features = df[['V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10']]

scaler = StandardScaler()
scaled_features = scaler.fit_transform(selected_features)

wcss = []  # Within-Cluster-Sum-of-Squares
for i in range(1, 11):
    kmeans = KMeans(n_clusters=i, init='k-means++', max_iter=300, n_init=10, random_state=0)
    kmeans.fit(scaled_features)
    wcss.append(kmeans.inertia_)

plt.plot(range(1, 11), wcss)
plt.xlabel('Number of clusters')
plt.ylabel('WCSS')
plt.show()

optimal_k = 3
kmeans = KMeans(n_clusters=optimal_k, init='k-means++', max_iter=300, n_init=10, random_state=0)
cluster_labels = kmeans.fit_predict(scaled_features)
df['Cluster'] = cluster_labels
plt.scatter(df['V1'], df['V2'], c=df['Cluster'], cmap='rainbow')
plt.title('K-Means Clusters')
plt.show()